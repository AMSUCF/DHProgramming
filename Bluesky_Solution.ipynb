{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMSUCF/DHProgramming/blob/main/Bluesky_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxPhfdqEUpG-"
      },
      "source": [
        "# Social Media Analysis with AI Assistance\n",
        "*Building on Your Combinatorial Text Experience*\n",
        "\n",
        "## Getting Started Reminders\n",
        "\n",
        "### Before You Begin:\n",
        "1. **Set up Bluesky credentials** in Colab Secrets (left sidebar → 🔑)\n",
        "   - Add `BLUESKY_USERNAME` (your.handle.bsky.social)\n",
        "   - Add `BLUESKY_APP_PASSWORD` (generate in Bluesky Settings → App Passwords)\n",
        "\n",
        "2. **Review AI assistance levels** from the workshop:\n",
        "   - **Level 1:** Code comprehension & debugging\n",
        "   - **Level 2:** Conceptual application & adaptation  \n",
        "   - **Level 3:** Critical evaluation & extension\n",
        "\n",
        "### Jupyter Workflow Tips:\n",
        "- **Test in new cells** before modifying working code\n",
        "- **Comment out** previous versions instead of deleting\n",
        "- **Use markdown cells** to document your AI conversations\n",
        "- **Save successful iterations** before experimenting further\n",
        "\n",
        "### Recommended Cell Organization:\n",
        "1. **Setup Cell:** Libraries and authentication (run once)\n",
        "2. **Data Collection Cell:** API calls (modify and re-run as needed)\n",
        "3. **Processing Cell:** Clean and structure your data\n",
        "4. **Analysis Cells:** Individual analyses (iterate with AI)\n",
        "5. **Visualization Cell:** Final outputs and interpretations\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gQd1tIKUpHA"
      },
      "source": [
        "## Step 1: Setup and Authentication\n",
        "*Add your code cell below to install libraries and authenticate with Bluesky*\n",
        "\n",
        "**AI Prompt Starters:**\n",
        "- \"Help me install the required libraries for Bluesky API and data analysis\"\n",
        "- \"I'm getting an authentication error. What might be wrong?\"\n",
        "- \"Show me how to securely store and access API credentials in Colab\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Install just the required libraries to access the Bluesky API\n",
        "\n",
        "!pip install atproto\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1qrJ_d-EZaN1",
        "outputId": "6bebaad3-5fbd-4fb1-c097-375b6ee583a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting atproto\n",
            "  Downloading atproto-0.0.61-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: click<9,>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from atproto) (8.2.1)\n",
            "Requirement already satisfied: cryptography<46,>=41.0.7 in /usr/local/lib/python3.11/dist-packages (from atproto) (43.0.3)\n",
            "Collecting dnspython<3,>=2.4.0 (from atproto)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (0.28.1)\n",
            "Collecting libipld<4,>=3.0.1 (from atproto)\n",
            "  Downloading libipld-3.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2.7 in /usr/local/lib/python3.11/dist-packages (from atproto) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (4.13.2)\n",
            "Collecting websockets<14,>=12 (from atproto)\n",
            "  Downloading websockets-13.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<46,>=41.0.7->atproto) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.25.0->atproto) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.25.0->atproto) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.25.0->atproto) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.25.0->atproto) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.25.0->atproto) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.7->atproto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.7->atproto) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.7->atproto) (0.4.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<46,>=41.0.7->atproto) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.25.0->atproto) (1.3.1)\n",
            "Downloading atproto-0.0.61-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.4/380.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libipld-3.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (682 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.4/682.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, libipld, dnspython, atproto\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.7.4 requires websockets>=14.0, but you have websockets 13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed atproto-0.0.61 dnspython-2.7.0 libipld-3.0.1 websockets-13.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Authenticate me to the Bluesky API using the secret names above\n",
        "\n",
        "from google.colab import userdata\n",
        "from atproto import Client\n",
        "\n",
        "# Bluesky authentication\n",
        "bluesky_client = Client()\n",
        "try:\n",
        "  bluesky_client.login(userdata.get('BLUESKY_USERNAME'), userdata.get('BLUESKY_APP_PASSWORD'))\n",
        "  print(\"Bluesky authentication successful!\")\n",
        "except Exception as e:\n",
        "  print(f\"Bluesky authentication failed: {e}\")\n",
        "  print(\"Please check your BLUESKY_USERNAME and BLUESKY_APP_PASSWORD in Colab Secrets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CmTQMIIadvQ",
        "outputId": "c92c677d-33e5-4b57-e8dd-5f6441985496"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bluesky authentication successful!\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# search for up to 10 matching posts\n",
        "resp = bluesky_client.app.bsky.feed.search_posts({\n",
        "    \"q\": \"#ai\",\n",
        "    \"limit\": 10\n",
        "})\n",
        "\n",
        "for post in resp.posts:\n",
        "    author = post.author.handle\n",
        "    text   = post.record.text\n",
        "    print(f\"@{author}: {text}\\n\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqRBA7jw44XR",
        "outputId": "e4a3d6ca-4261-4f0b-ab47-460c101cfc00"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@mrblackk.bsky.social: Art from my Brain \n",
            "\n",
            "Dragon Ball \n",
            "\n",
            "#art #artist #love #drawing #aiart #artwork #dragontuesday #ai #like #illustration #digitalart #aiartcommunity #gothic #gothaesthetic #picoftheday #spooky #midjourney #aiart #midjourneyart #skullart #midjourneyai #darkart #aiartist #epic #artoftheday #aiartists\n",
            "\n",
            "@bluesky.awakari.com: KOLO Launches Next-Generation Digital Wallet with Worldwide Debit Card, Bridging Digital Assets and Everyday Spending Astana City, Kazakhstan, [May 28th, 2025] — KOLO, a leading web3 project, has officially launched its innovative digital wallet with ...\n",
            "\n",
            "| Details | Interest | Feed |\n",
            "\n",
            "@mrblackk.bsky.social: Self Portrait \n",
            "\n",
            "#art #artist #love #drawing #aiart #artwork #photooftheday #painting #ai #like #illustration #digitalart #aiartcommunity #gothic #gothaesthetic #picoftheday #spooky #midjourney #aiart #midjourneyart #skullart #midjourneyai #darkart #aiartist #epic #artoftheday #aiartists\n",
            "\n",
            "@mrblackk.bsky.social: Art from my Brain \n",
            "\n",
            "Caesar \n",
            "\n",
            "#Ai #rome #roman #PromptCraft #Aimagination #SynthArt #AiPortrait #AiReal #SFWAi #FantasyAi #AiArt #AiIllustration #AiIllust #AiArtCommunity #PromptArt #AiArtist\n",
            "\n",
            "@larrycornett.coach: The world is changing rapidly, and it is clear that #AI fluency will be required if you want to keep your job, especially if you work in #tech and perform some sort of #knowledgework. \n",
            "\n",
            "So, what are you doing to stay ahead of this shift?\n",
            "\n",
            "#careerchange #careerpaths #careercoach\n",
            "\n",
            "@littlebirdtrading.bsky.social: Free idea: Buy $EWM above 25.05\n",
            "\n",
            "#AI developed #algos full report for May 27th\n",
            "littlebirdtrading.substack.com/p/updated-mo...\n",
            "\n",
            "Please subscribe to unlock full coverage list including\n",
            "7 model #portfolios\n",
            "& 100+ assets in #Stocks $MSTR #Bonds $TIP #Currencies $UUP #Crypto $BTC #Commodities $DBA\n",
            "\n",
            "@mrblackk.bsky.social: Art from my Brain \n",
            "\n",
            "The Council\n",
            "\n",
            "#art #artist #love #aiart #artwork #photooftheday #ai #like #illustration #digitalart #aiartcommunity #gothic #gothaesthetic #picoftheday #spooky #midjourney #aiart #midjourneyart #skullart #midjourneyai #darkart #aiartist #epic #artoftheday #aiartists\n",
            "\n",
            "@tryart-anime.bsky.social: Bone Girl \n",
            "#背骨の日 #ai #aiart #aigirl #anime #アニメ #aiアニメ #aiイラスト #aiガール #画像生成ai #TryArt\n",
            "\n",
            "@technovangelist.bsky.social: MCP unlocks AI tool power! ⚡ Learn how to create a platform, automate tasks, & even build apps without coding. #AI #MCP ##n8n https://youtu.be/OmWJPJ1CR7M\n",
            "\n",
            "@gaiety.bsky.social: #Art #AI #Male #Homoerotic #gayart #gayAI #AItwink #AImodel\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assuming you have `all_posts` already populated...\n",
        "import pandas as pd\n",
        "\n",
        "records = []\n",
        "for post in all_posts:\n",
        "    author = post.author\n",
        "    rec    = post.record\n",
        "\n",
        "    # base fields\n",
        "    row = {\n",
        "        \"author_handle\":         author.handle,\n",
        "        \"author_display_name\":   author.display_name,\n",
        "        \"author_did\":            author.did,\n",
        "        \"author_avatar_url\":     author.avatar,\n",
        "        \"author_created_at\":     author.created_at,    # snake_case\n",
        "        \"post_text\":             rec.text.replace(\"\\n\", \" \"),\n",
        "        \"post_created_at\":       rec.created_at,       # snake_case\n",
        "        \"post_uri\":              post.uri,\n",
        "    }\n",
        "\n",
        "    # any embedded URLs in facets (e.g. links)\n",
        "    linked_urls = []\n",
        "    if rec.facets:\n",
        "        for facet in rec.facets:\n",
        "            for feat in facet.features:\n",
        "                # feature types can vary; Link has a `.uri`\n",
        "                if hasattr(feat, \"uri\"):\n",
        "                    linked_urls.append(feat.uri)\n",
        "    row[\"linked_urls\"] = \",\".join(linked_urls) if linked_urls else None\n",
        "\n",
        "    # if you want the post’s embed object (e.g. an image/video)\n",
        "    if rec.embed:\n",
        "        # different embed types have different attributes; here’s a generic catch:\n",
        "        row[\"embed\"] = rec.embed.dict()\n",
        "    else:\n",
        "        row[\"embed\"] = None\n",
        "\n",
        "    records.append(row)\n",
        "\n",
        "# build the DataFrame\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "# inspect columns\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# and write out as before\n",
        "df.to_csv(\"/content/ai_posts_flat.csv\", index=False)\n",
        "print(f\"Wrote {len(df)} rows to /content/ai_posts_flat.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_D8YXiM7XFA",
        "outputId": "52e4342a-db5e-448f-f300-a194d4230641"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['author_handle', 'author_display_name', 'author_did', 'author_avatar_url', 'author_created_at', 'post_text', 'post_created_at', 'post_uri', 'linked_urls', 'embed']\n",
            "Wrote 1000 rows to /content/ai_posts_flat.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-7023f00ac483>:34: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  row[\"embed\"] = rec.embed.dict()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLRV9Qx3UpHB"
      },
      "source": [
        "## Step 2: Data Collection\n",
        "*Create cells below to collect your research corpus from Bluesky*\n",
        "\n",
        "**Consider:**\n",
        "- What users or hashtags relate to your research interest?\n",
        "- How many posts do you need for meaningful analysis?\n",
        "- What time period should your data cover?\n",
        "\n",
        "**AI Prompt Starters:**\n",
        "- \"Help me write a function to collect posts from specific users\"\n",
        "- \"How do I search for posts containing certain hashtags?\"\n",
        "- \"My data collection is only getting a few posts. How can I get more?\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R2hFfkcRdVKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGQOIeclUpHB"
      },
      "source": [
        "## Step 3: Data Processing\n",
        "*Transform raw API data into analysis-ready format*\n",
        "\n",
        "**Key Tasks:**\n",
        "- Convert API responses to pandas DataFrame\n",
        "- Extract relevant features (timestamps, engagement, text length, etc.)\n",
        "- Clean and validate your data\n",
        "\n",
        "**AI Prompt Starters:**\n",
        "- \"Convert this Bluesky API response into a pandas DataFrame\"\n",
        "- \"Help me extract and clean timestamps from social media data\"\n",
        "- \"I have missing values in my dataset. How should I handle them?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKfR3MCvUpHB"
      },
      "source": [
        "## Step 4: Content Analysis\n",
        "*Analyze patterns in your collected text data*\n",
        "\n",
        "**Analysis Ideas:**\n",
        "- Categorize posts by topic or theme\n",
        "- Analyze word frequency and key terms\n",
        "- Compare content types and their engagement\n",
        "\n",
        "**AI Prompt Starters:**\n",
        "- \"Create a function to categorize posts based on academic, literary, or general content\"\n",
        "- \"How do I analyze word frequency in my social media corpus?\"\n",
        "- \"My text categorization isn't working well. Help me debug and improve it\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvqxI4XQUpHC"
      },
      "source": [
        "## Step 5: Temporal Analysis\n",
        "*Examine patterns over time in your data*\n",
        "\n",
        "**Questions to Explore:**\n",
        "- When are users most active?\n",
        "- How does engagement vary by time of day or day of week?\n",
        "- Are there notable spikes or patterns in posting activity?\n",
        "\n",
        "**AI Prompt Starters:**\n",
        "- \"Analyze posting patterns by hour and day of week in my dataset\"\n",
        "- \"How do I identify unusual activity periods in my temporal data?\"\n",
        "- \"Create visualizations showing posting activity over time\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrUWPucuUpHC"
      },
      "source": [
        "## Step 6: Visualization\n",
        "*Create compelling visualizations of your findings*\n",
        "\n",
        "**Visualization Goals:**\n",
        "- Make patterns visible and interpretable\n",
        "- Support your analytical arguments\n",
        "- Communicate findings to your intended audience\n",
        "\n",
        "**AI Prompt Starters:**\n",
        "- \"Create a comprehensive dashboard showing key patterns in my social media data\"\n",
        "- \"This scatter plot is too crowded. How can I make it clearer?\"\n",
        "- \"What additional visualizations would reveal patterns I might be missing?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cFsTboVUpHD"
      },
      "source": [
        "## Step 7: Interpretation and Analysis\n",
        "*Connect computational findings to your research questions*\n",
        "\n",
        "**Critical Questions:**\n",
        "- What do these patterns reveal about the community or phenomenon you're studying?\n",
        "- How do computational findings compare to traditional research methods?\n",
        "- What are the limitations of your approach and data?\n",
        "\n",
        "**AI Prompt Starters:**\n",
        "- \"Help me interpret these engagement patterns in the context of [your discipline]\"\n",
        "- \"What are the potential biases in my social media dataset?\"\n",
        "- \"How can I validate these computational results against other sources?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo04oKqBUpHD"
      },
      "source": [
        "## Advanced Extensions (Optional)\n",
        "*For deeper analysis if you have time and interest*\n",
        "\n",
        "**Possible Extensions:**\n",
        "- Network analysis of user interactions\n",
        "- Topic modeling to identify themes\n",
        "- Sentiment analysis of posts\n",
        "- Comparison with other datasets or time periods\n",
        "\n",
        "**AI Prompt Starters:**\n",
        "- \"Help me implement basic network analysis for user mentions in my data\"\n",
        "- \"Create a topic modeling analysis to identify themes in my corpus\"\n",
        "- \"How do I add sentiment analysis to my existing content analysis?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOv5L22GUpHD"
      },
      "source": [
        "---\n",
        "## Notes and Reflections\n",
        "*Use this space to document your process, interesting findings, and AI interactions*\n",
        "\n",
        "### What worked well:\n",
        "-\n",
        "\n",
        "### Challenges encountered:\n",
        "-\n",
        "\n",
        "### Most helpful AI interactions:\n",
        "-\n",
        "\n",
        "### Key insights from your analysis:\n",
        "-\n",
        "\n",
        "### Questions for further research:\n",
        "-"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}