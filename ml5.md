## Exercise: Creative Code with ML5

In this exercise, we'll deploy [Teachable Machine](imagescraping.md) and [ml5](ml5/index.html) to build an original web implementation of a responsive interface. This should be a creative project and doesn't need to have any "purpose" beyond an aesthetic response to webcam input. 

Your experience can either use a custom model trained on your own webcam input, as in the Rock Paper Scissors demo, or it can make use of an existing web-optimized model. The piece should either work from user tracking (if using the capacities of face and hand recognition) or distinguish between at least two types of input with a different response.

We'll work through these examples and learn from their approaches:

- [Kinetic Type and FaceMesh](https://editor.p5js.org/codingtrain/sketches/CITZ-7eyA)
- [Falling Coins](https://editor.p5js.org/pattvira/sketches/DCTLTHUyU)
- [Interactive Fridge Magnets](https://editor.p5js.org/pattvira/sketches/f3nZuIPZi)

Here's a few of my examples:

- [Hand and text](https://openprocessing.org/sketch/2557140)
- [Sentiment Face Play](https://openprocessing.org/sketch/2561411)
- [ml5 libraries combined](https://openprocessing.org/sketch/2563749)

I recommend the [ml5.js Coding Train Videos](https://youtu.be/2h8VArJ3gnQ?si=A4eMADxQ529uiY0x) for additional references on the current capabilities of the library.